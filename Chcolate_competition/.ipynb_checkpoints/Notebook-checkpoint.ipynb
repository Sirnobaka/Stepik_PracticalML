{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\n",
    "        'font.size': 14,\n",
    "        'axes.titlesize': 20,\n",
    "        'axes.labelsize': 20,\n",
    "        'xtick.labelsize': 20,\n",
    "        'ytick.labelsize': 20,\n",
    "        'font.size': 20,\n",
    "        'figure.figsize': (10, 7),\n",
    "        'axes.grid': True,\n",
    "        'grid.linestyle': '-',\n",
    "        'grid.alpha': 0.3,\n",
    "        'lines.markersize': 5.0,\n",
    "        'xtick.minor.visible': True,\n",
    "        'xtick.direction': 'in',\n",
    "        'xtick.major.size': 20.0,\n",
    "        'xtick.minor.size': 10.0,\n",
    "        'xtick.top': False,\n",
    "        'xtick.bottom': True,\n",
    "        'ytick.minor.visible': True,\n",
    "        'ytick.direction': 'in',\n",
    "        'ytick.major.size': 12.0,\n",
    "        'ytick.minor.size': 6.0,\n",
    "        'ytick.right': True,\n",
    "        'errorbar.capsize': 0.0,\n",
    "    })\n",
    "\n",
    "# https://www.kaggle.com/competitions/practical-ml-chocolate/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-heading",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-chemical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Specific Bean Origin</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cocoa Percent</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean Type</th>\n",
       "      <th>Broad Bean Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Willie's Cacao</td>\n",
       "      <td>Rio Caribe</td>\n",
       "      <td>457</td>\n",
       "      <td>2009</td>\n",
       "      <td>72%</td>\n",
       "      <td>U.K.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beschle (Felchlin)</td>\n",
       "      <td>Ocumare, Premier Cru, Quizas No. 2</td>\n",
       "      <td>508</td>\n",
       "      <td>2010</td>\n",
       "      <td>72%</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>3.50</td>\n",
       "      <td></td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dark Forest</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>1554</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.00</td>\n",
       "      <td></td>\n",
       "      <td>Tanzania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brasstown aka It's Chocolate</td>\n",
       "      <td>Cooproagro</td>\n",
       "      <td>1125</td>\n",
       "      <td>2013</td>\n",
       "      <td>72%</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinitario</td>\n",
       "      <td>Dominican Republic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pralus</td>\n",
       "      <td>Java, Indonesie</td>\n",
       "      <td>32</td>\n",
       "      <td>2006</td>\n",
       "      <td>75%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Criollo</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company                Specific Bean Origin   REF  \\\n",
       "0                Willie's Cacao                          Rio Caribe   457   \n",
       "1            Beschle (Felchlin)  Ocumare, Premier Cru, Quizas No. 2   508   \n",
       "2                   Dark Forest                            Tanzania  1554   \n",
       "3  Brasstown aka It's Chocolate                          Cooproagro  1125   \n",
       "4                        Pralus                     Java, Indonesie    32   \n",
       "\n",
       "   Review Cocoa Percent Company Location  Rating   Bean Type  \\\n",
       "0    2009           72%             U.K.    3.25  Trinitario   \n",
       "1    2010           72%      Switzerland    3.50               \n",
       "2    2015           70%           U.S.A.    3.00               \n",
       "3    2013           72%           U.S.A.    3.00  Trinitario   \n",
       "4    2006           75%           France    3.50     Criollo   \n",
       "\n",
       "    Broad Bean Origin  \n",
       "0           Venezuela  \n",
       "1           Venezuela  \n",
       "2            Tanzania  \n",
       "3  Dominican Republic  \n",
       "4           Indonesia  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('chocolate_train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data has 9 columns and 1255 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data has {df_train.shape[1]} columns and {df_train.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quiet-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1255 entries, 0 to 1254\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Company               1255 non-null   object \n",
      " 1   Specific Bean Origin  1255 non-null   object \n",
      " 2   REF                   1255 non-null   int64  \n",
      " 3   Review                1255 non-null   int64  \n",
      " 4   Cocoa Percent         1255 non-null   object \n",
      " 5   Company Location      1255 non-null   object \n",
      " 6   Rating                1255 non-null   float64\n",
      " 7   Bean Type             1254 non-null   object \n",
      " 8   Broad Bean Origin     1254 non-null   object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 88.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accepted-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in categorical columns\n",
      "Company: 376\n",
      "Specific Bean Origin: 762\n",
      "Cocoa Percent: 40\n",
      "Company Location: 58\n",
      "Bean Type: 38\n",
      "Broad Bean Origin: 84\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique values in categorical columns')\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'O':\n",
    "        print(f'{col}: {df_train[col].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "functional-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make percentage float\n",
    "df_train['Cocoa Percent'] = df_train['Cocoa Percent'].apply(lambda x: float(x.strip('%')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solar-reminder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REF</th>\n",
       "      <th>Review</th>\n",
       "      <th>Cocoa Percent</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1255.000000</td>\n",
       "      <td>1255.000000</td>\n",
       "      <td>1255.000000</td>\n",
       "      <td>1255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1045.152191</td>\n",
       "      <td>2012.382470</td>\n",
       "      <td>71.790438</td>\n",
       "      <td>3.176494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>551.284249</td>\n",
       "      <td>2.922499</td>\n",
       "      <td>6.397448</td>\n",
       "      <td>0.478948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>593.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1077.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1514.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1952.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               REF       Review  Cocoa Percent       Rating\n",
       "count  1255.000000  1255.000000    1255.000000  1255.000000\n",
       "mean   1045.152191  2012.382470      71.790438     3.176494\n",
       "std     551.284249     2.922499       6.397448     0.478948\n",
       "min       5.000000  2006.000000      46.000000     1.000000\n",
       "25%     593.000000  2010.000000      70.000000     2.750000\n",
       "50%    1077.000000  2013.000000      70.000000     3.250000\n",
       "75%    1514.000000  2015.000000      75.000000     3.500000\n",
       "max    1952.000000  2017.000000     100.000000     5.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-leone",
   "metadata": {},
   "source": [
    "## 1.1 Handling empty cells and nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "speaking-vatican",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Company', 'Specific Bean Origin', 'Company Location', 'Bean Type',\n",
       "       'Broad Bean Origin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[df_train.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recorded-episode",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company                 0\n",
       "Specific Bean Origin    0\n",
       "REF                     0\n",
       "Review                  0\n",
       "Cocoa Percent           0\n",
       "Company Location        0\n",
       "Rating                  0\n",
       "Bean Type               1\n",
       "Broad Bean Origin       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prerequisite-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "heavy-spirituality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company                   0\n",
       "Specific Bean Origin      0\n",
       "REF                       0\n",
       "Review                    0\n",
       "Cocoa Percent             0\n",
       "Company Location          0\n",
       "Rating                    0\n",
       "Bean Type               628\n",
       "Broad Bean Origin        55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_cell = df_train['Bean Type'].value_counts().index[0]\n",
    "(df_train == empty_cell).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-juice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-custody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-taylor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_cell = df_train['Bean Type'].value_counts().index[0]\n",
    "df_train['Bean Type'] = df_train['Bean Type'].replace({empty_cell: \"Unknown\"})\n",
    "df_train['Broad Bean Origin'] = df_train['Broad Bean Origin'].replace({empty_cell: \"Unknown\"})\n",
    "df_train['Company Location'] = df_train['Company Location'].replace({'Niacragua': 'Nicaragua'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-bulletin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "greek-press",
   "metadata": {},
   "source": [
    "## 1.2 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('chocolate_test_new.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Bean Type'] = df_test['Bean Type'].replace({empty_cell: \"Unknown\"})\n",
    "df_test['Broad Bean Origin'] = df_test['Broad Bean Origin'].replace({empty_cell: \"Unknown\"})\n",
    "df_test['Cocoa Percent'] = df_test['Cocoa Percent'].apply(lambda x: float(x.strip('%')))\n",
    "\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Empty cells')\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'O':\n",
    "        print(f'{col}: {(df_test[col]==empty_cell).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = df_train.columns[df_train.dtypes == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique values in categorical columns')\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if df_test[col].dtype == 'O':\n",
    "        print(f'{col}: {df_test[col].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-remains",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_train['Cocoa Percent'], df_train['Rating'], c='black')\n",
    "plt.xlabel('Cocoa percent')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Rating'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Rating')['Cocoa Percent'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution(data, title, x_label, y_label, figsize=(10,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.style.use('seaborn-pastel')\n",
    "    density = sns.barplot(x=data.index, y=data.values)\n",
    "    title = plt.title(title, fontdict={'fontsize': 20})\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cocoa_percent_dist = df_train.groupby('Rating')['Cocoa Percent'].mean()\n",
    "\n",
    "distribution(data=rating_cocoa_percent_dist,\n",
    "             title='Mean cocoa percent in rating',\n",
    "             x_label='Rating',\n",
    "             y_label='Cocoa percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-temple",
   "metadata": {},
   "source": [
    "Chocolate with very high percentage of cocoa may have lower rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Rating')['REF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(df_train['REF'], df_train['Rating'], bins=[20, 16])\n",
    "plt.xlabel('REF')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df_train, x=\"REF\", y=\"Rating\", cbar=True, bins=[20, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cocoa_percent_dist = df_train.groupby('Rating')['REF'].mean()\n",
    "\n",
    "distribution(data=rating_cocoa_percent_dist,\n",
    "             title='Mean REF in rating',\n",
    "             x_label='Rating',\n",
    "             y_label='REF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_rating = df_train['Rating'].nunique()\n",
    "unique_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-pakistan",
   "metadata": {},
   "source": [
    "Chocolate wtih low REF tends to have low or very high rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_train['Review'], df_train['REF'])\n",
    "plt.xlabel('Review [Year]')\n",
    "plt.ylabel('REF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Review', 'REF']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-kitchen",
   "metadata": {},
   "source": [
    "REF and Review are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Review')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_cocoa_percent_dist = df_train.groupby('Review')['Rating'].mean()\n",
    "\n",
    "distribution(data=rating_cocoa_percent_dist,\n",
    "             title='Mean rating per year',\n",
    "             x_label='Review [Year]',\n",
    "             y_label='Rating',\n",
    "             figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Bean Type'] == 'Unknown', ['Bean Type', 'Specific Bean Origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['Bean Type'] == 'Unknown']['Specific Bean Origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['Bean Type'] != 'Unknown']['Specific Bean Origin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_bins = int((df_train.Rating.max() - df_train.Rating.min()) / 0.25)\n",
    "\n",
    "plt.hist(df_train.Rating, bins=rating_bins)\n",
    "plt.xlabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-acceptance",
   "metadata": {},
   "source": [
    "Inference:\n",
    "* Chocolate with very high percentage of cocoa may have lower rating\n",
    "* Chocolate with low REF rated lower\n",
    "* REF and Review (year) are highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-redhead",
   "metadata": {},
   "source": [
    "## 2.1 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.rcParams.update({\n",
    "    'xtick.labelsize': 15,\n",
    "    'ytick.labelsize': 15,\n",
    "})\n",
    "sns.heatmap(df_train.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import association_metrics as am\n",
    "\n",
    "XC = df_train.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x)\n",
    "cramersv = am.CramersV(XC)\n",
    "cramersv.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = df_test.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x)\n",
    "cramersv = am.CramersV(XC)\n",
    "cramersv.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Company', 'Company Location']:\n",
    "    print(f'{col}: {df_train[col].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-token",
   "metadata": {},
   "source": [
    "Correlated features (may drop one from each pair):\n",
    "* REF and Review\n",
    "* Company and Company Location\n",
    "* Broad Bean Origin and Specific Bean Origin\n",
    "* Specific Bean Origin and Bean Type\n",
    "\n",
    "May be we should drop \"Bean Type\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_short = df_train.drop(['Company', 'Specific Bean Origin'], axis=1)\n",
    "df_test_short = df_test.drop(['Company', 'Specific Bean Origin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols_short = df_train_short.columns[df_train_short.dtypes==object]\n",
    "for col in object_cols_short:\n",
    "    out_mask = ~np.isin(df_test_short[col].unique(), df_train_short[col].unique())\n",
    "    print(out_mask.sum())\n",
    "    print(f'{col} presented in test but not in train:')\n",
    "    print('-'*70)\n",
    "    print(*df_test_short[col].unique()[out_mask], sep='\\n')\n",
    "    print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_short[df_test_short['Company Location'] == 'Martinique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_short[df_test_short['Company Location'].apply(lambda x: x in ['Martinique', 'Philippines'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_short[df_test_short['Broad Bean Origin'].apply(lambda x: x in ['Martinique', 'Philippines'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-layer",
   "metadata": {},
   "source": [
    "# 3. Feature ingeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-checklist",
   "metadata": {},
   "source": [
    "## Broad company location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-limit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.groupby('Company Location').agg({'Rating': 'mean', 'Company Location': 'count'})\\\n",
    "    .sort_values(by='Rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_locations = {'Europe': ['U.K.', 'Switzerland', 'France', 'Belgium', 'Spain', 'Italy',\n",
    "                             'Austria', 'Sweden', 'Ireland', 'Poland', 'Hungary', 'Germany',\n",
    "                             'Denmark', 'Lithuania', 'Scotland', 'Finland', 'Iceland', \n",
    "                             'Amsterdam', 'Wales', 'Netherlands', 'Portugal', 'Czech Republic'],\n",
    "                  'North America': ['U.S.A.', 'Canada'],\n",
    "                  'Africa': ['Madagascar', 'South Africa', 'Ghana', 'Sao Tome'],\n",
    "                  'Caribbean': ['Colombia', 'Venezuela', 'Honduras', 'Guatemala',\n",
    "                               'Domincan Republic', 'Grenada', 'Puerto Rico', 'Costa Rica',\n",
    "                               'St. Lucia', 'Nicaragua', 'Martinique', 'Niacragua'],\n",
    "                   'Asia & Oceania': ['Japan', 'Vietnam', 'Philippines', 'Fiji', 'Australia',\n",
    "                           'South Korea', 'Israel', 'Singapore', 'India', 'Russia',\n",
    "                           'New Zealand'],\n",
    "                   'South America': ['Ecuador', 'Brazil', 'Peru', 'Eucador', 'Argentina',\n",
    "                                    'Chile', 'Mexico', 'Bolivia', 'Suriname']\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_in_list(location):\n",
    "    for k, v in broad_locations.items():\n",
    "        if location in v:\n",
    "            return k\n",
    "    return 'Other'\n",
    "\n",
    "df_train['Broad Company Location'] = df_train['Company Location'].apply(lambda x: location_in_list(x))\n",
    "df_test['Broad Company Location'] = df_test['Company Location'].apply(lambda x: location_in_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Broad Company Location')\\\n",
    "    .agg({'Rating': ['mean', 'std'], 'Broad Company Location': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "ratings = [df_train.loc[df_train['Broad Company Location'] == i, ['Rating']].values[:, 0] for i in df_train['Broad Company Location'].unique()]\n",
    "f_test = f_oneway(*ratings)\n",
    "print('One way anova test')\n",
    "print(f'F statistics = {f_test.statistic}')\n",
    "print(f'p-value = {f_test.pvalue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_train['Broad Bean Origin'].unique():\n",
    "    if not i in df_train[\"Company Location\"].unique():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_locations_bean = {'Europe': ['U.K.', 'Switzerland', 'France', 'Belgium', 'Spain', 'Italy',\n",
    "                             'Austria', 'Sweden', 'Ireland', 'Poland', 'Hungary', 'Germany',\n",
    "                             'Denmark', 'Lithuania', 'Scotland', 'Finland', 'Iceland', \n",
    "                             'Amsterdam', 'Wales', 'Netherlands', 'Portugal', 'Czech Republic'],\n",
    "                  'North America': ['U.S.A.', 'Canada'],\n",
    "                  'Africa': ['Madagascar', 'South Africa', 'Ghana', 'Sao Tome', 'Tanzania',\n",
    "                             'Indonesia', 'Congo', 'Liberia', 'Principe', 'Sao Tome & Principe',\n",
    "                            'Gabon', 'Ivory Coast', 'Uganda', 'Nigeria', 'West Africa'],\n",
    "                  'Caribbean': ['Colombia', 'Venezuela', 'Honduras', 'Guatemala',\n",
    "                               'Domincan Republic', 'Grenada', 'Puerto Rico', 'Costa Rica',\n",
    "                               'St. Lucia', 'Nicaragua', 'Martinique', 'Niacragua', 'Cost Rica, Ven',\n",
    "                               'Trinidad', 'Panama', 'Jamaica', 'Haiti', 'Cuba', 'Venezuela, Ghana',\n",
    "                               'Ven.,Ecu.,Peru,Nic.', 'Tobago', 'Carribean(DR/Jam/Tri)',\n",
    "                               'Venezuela, Java', 'Ven, Bolivia, D.R.', 'Venezuela, Carribean',\n",
    "                               'Dominican Republic', 'Carribean'],\n",
    "                   'Asia & Oceania': ['Japan', 'Vietnam', 'Philippines', 'Fiji', 'Australia',\n",
    "                                      'South Korea', 'Israel', 'Singapore', 'India', 'Russia',\n",
    "                                      'New Zealand', 'Papua New Guinea', 'Hawaii', 'Solomon Islands',\n",
    "                                      'Sri Lanka', 'Malaysia', 'Samoa', 'Philippines', 'Togo',\n",
    "                                      'Vanuatu'],\n",
    "                   'South America': ['Ecuador', 'Brazil', 'Peru', 'Eucador', 'Argentina',\n",
    "                                    'Chile', 'Mexico', 'Bolivia', 'Suriname', 'Peru, Dom. Rep',\n",
    "                                    'Central and S. America', 'Colombia, Ecuador', 'Dom. Rep., Madagascar',\n",
    "                                    'South America', 'Belize', 'El Salvador'],\n",
    "                   'Mixed': ['Trinidad, Ecuador', 'South America, Africa', 'PNG, Vanuatu, Mad',\n",
    "                            'Mad., Java, PNG', 'Peru, Mad., Dom. Rep.', 'Indonesia, Ghana', 'Madagascar & Ecuador',\n",
    "                            'Venez,Africa,Brasil,Peru,Mex', 'DR, Ecuador, Peru', 'Dominican Rep., Bali',\n",
    "                            'Peru, Madagascar', 'Venezuela, Dom. Rep.', 'Peru, Ecuador, Venezuela',\n",
    "                            'Ven., Trinidad, Mad.', 'Ven., Indonesia, Ecuad.', 'Ghana, Domin. Rep',\n",
    "                            'Peru, Belize', 'Guat., D.R., Peru, Mad., PNG']\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-condition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_in_list(location, locations_dict=broad_locations):\n",
    "    for k, v in locations_dict.items():\n",
    "        if location in v:\n",
    "            return k\n",
    "    return 'Other'\n",
    "\n",
    "df_train['Bean origin world'] = df_train['Broad Bean Origin'].apply(lambda x: location_in_list(x, broad_locations_bean))\n",
    "df_test['Bean origin world'] = df_test['Broad Bean Origin'].apply(lambda x: location_in_list(x, broad_locations_bean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Bean origin world'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Bean origin world').agg({'Rating': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_names(string):\n",
    "    answer = 0\n",
    "    for i  in [',', '&']:\n",
    "        if i in string:\n",
    "            answer = 1\n",
    "    return answer\n",
    "\n",
    "df_train['Multiple bean origins'] = df_train['Broad Bean Origin'].apply(lambda x: multiple_names(x))\n",
    "df_test['Multiple bean origins'] = df_test['Broad Bean Origin'].apply(lambda x: multiple_names(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Multiple bean origins')\\\n",
    "    .agg({'Rating': ['mean', 'std'], 'Multiple bean origins': 'count'})\n",
    "    #.rename({'Multiple bean origins': 'count'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries producing the best chocolate (according to internet)\n",
    "best_production_countries = ['Belgium', 'Switzerland', 'Italy', 'Germany', 'Austria', 'Poland',\n",
    "                             'Ecuador', 'Japan', 'New Zealand', 'Sweden', 'Spain', 'Mexico', 'Brazil',\n",
    "                             'India', 'Peru', 'Australia', 'U.K.',\n",
    "                             'Indonesia', 'Tahiland', 'Philippines', 'Ivory Coast', 'U.S.A.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(best_production_countries)[~np.in1d(best_production_countries, df_train['Company Location'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Best Production'] = df_train['Company Location'].apply(lambda x: int(x in best_production_countries))\n",
    "df_test['Best Production'] = df_train['Company Location'].apply(lambda x: int(x in best_production_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Best Production').agg(MeanRating=('Rating', 'mean'),\n",
    "                                        StdRating=('Rating', 'std'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_amount_productrion_countries = ['Cote d’Ivoire', 'Ghana', 'Indonesia', 'Nigeria',\n",
    "                                    'Ecuador', 'Cameroon', 'Brazil', 'Sierra Leone',\n",
    "                                    'Peru', 'Dominican Republic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Top Production Country'] = df_train['Broad Bean Origin'].apply(lambda x: int(x in top_amount_productrion_countries))\n",
    "df_test['Top Production Country'] = df_train['Broad Bean Origin'].apply(lambda x: int(x in top_amount_productrion_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Top Production Country')\\\n",
    "    .agg(MeanRating=('Rating', 'mean'),\n",
    "         StdRating=('Rating', 'std'),\n",
    "         Count=('Top Production Country', 'count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,12))\n",
    "plt.rcParams.update({\n",
    "    'xtick.labelsize': 15,\n",
    "    'ytick.labelsize': 15,\n",
    "})\n",
    "sns.heatmap(df_train.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_beans_list = ['Criollo', 'Trinitario'] \n",
    "\n",
    "def bean_in_list(bean_type, best_beans=best_beans_list):\n",
    "    answer = 0\n",
    "    for i in best_beans:\n",
    "        if i in bean_type:\n",
    "            answer = 1\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Best Bean Type'] = df_train['Bean Type'].apply(lambda x: bean_in_list(x, best_beans_list))\n",
    "df_test['Best Bean Type'] = df_train['Bean Type'].apply(lambda x: bean_in_list(x, best_beans_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.groupby('Best Bean Type')['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_beans_countries = ['Ecuador', 'Ivory Coast']\n",
    "\n",
    "df_train['Broad Bean Origin'].apply(lambda x: int(any([i in x for i in best_beans_countries])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_short = df_train.drop(['Company', 'Specific Bean Origin'], axis=1)\n",
    "df_test_short = df_test.drop(['Company', 'Specific Bean Origin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-responsibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-fitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-space",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "engaging-thinking",
   "metadata": {},
   "source": [
    "## 3.2 Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique values in categorical columns')\n",
    "\n",
    "for col in df_train_short.columns:\n",
    "    if df_train_short[col].dtype == 'O':\n",
    "        print(f'{col}: {df_train_short[col].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "XC = df_train_short.apply(lambda x: x.astype(\"category\") if x.dtype == \"object\" else x)\n",
    "cramersv = am.CramersV(XC)\n",
    "cramersv.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-manitoba",
   "metadata": {},
   "source": [
    "## 3.3 Write target encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTargetEncoder():\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.dict_cols = {k: dict() for k in self.columns}\n",
    "        print(\", \".join(self.columns))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        for col in self.columns:\n",
    "            print('-'*50, '\\n', col, '\\n', '-'*50)\n",
    "            for i in X[col].unique():\n",
    "                self.dict_cols[col][i] = y[X[col]==i].mean()\n",
    "                print(f'{i}: {self.dict_cols[col][i]}')\n",
    "            self.dict_cols[col]['Mean'] = y.mean()\n",
    "            print('Mean:', y.mean())\n",
    "                \n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            print(col)\n",
    "            values_avaliable = np.array(list(self.dict_cols[col].keys()))\n",
    "            values_not_avaliable = X[col].unique()[~np.in1d(X[col].unique(), values_avaliable)]\n",
    "            print('Not avliable:', values_not_avaliable)\n",
    "            X.loc[X[col].isin(values_not_avaliable), col] = self.dict_cols[col]['Mean']\n",
    "            X[col] = X[col].replace(self.dict_cols[col])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = df_train_s.columns[df_train_short.dtypes == object]\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-newspaper",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_encoder = MyTargetEncoder(obj_cols)\n",
    "my_encoder.fit(df_train_short.drop('Rating', axis=1), df_train_short['Rating'])\n",
    "df_train_new = my_encoder.transform(df_train_short.drop('Rating', axis=1))\n",
    "df_train_new['Rating'] = df_train_short['Rating']\n",
    "df_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = df_test_short.copy()\n",
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new = my_encoder.transform(df_test_new[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['Company Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-return",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interior-greensboro",
   "metadata": {},
   "source": [
    "# 4. Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-geneva",
   "metadata": {},
   "source": [
    "## 4.1 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_new.drop('Rating', axis=1)\n",
    "y = df_train_new['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_tree.predict(X_test)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "decision_tree_params = {'max_depth': np.arange(2, 10),\n",
    "                        'min_samples_leaf': np.arange(2, 20),\n",
    "                        'min_samples_split': np.arange(2, 40)}\n",
    "\n",
    "gs_tree = GridSearchCV(DecisionTreeRegressor(),\n",
    "                       decision_tree_params,\n",
    "                       scoring='r2',\n",
    "                       cv=3,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "gs_tree.fit(X_train, y_train)\n",
    "print(gs_tree.best_params_)\n",
    "print(gs_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = gs_tree.best_estimator_\n",
    "\n",
    "pd.DataFrame({'Feature': model_tree.feature_names_in_, 'Importance': model_tree.feature_importances_})\\\n",
    "    .sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_tree.predict(df_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_new['id'] = np.arange(len(df_test)) \n",
    "df_test_new['Rating'] = pred \n",
    "\n",
    "df_test_new[['id','Rating']].to_csv(\"tree_bad_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('tree_bad_submission.csv').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-adrian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-fault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "velvet-simulation",
   "metadata": {},
   "source": [
    "## 5.1 Decision tree test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('choco_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('chocolate_test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-singapore",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
